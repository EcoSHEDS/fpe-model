{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3803923/227242812.py:6: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "/opt/conda/envs/fpe-model.dev-amrita/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision.transforms import (\n",
    "    Resize,\n",
    "    RandomCrop,\n",
    "    CenterCrop,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomRotation,\n",
    "    ColorJitter,\n",
    "    Normalize,\n",
    "    Compose,\n",
    ")\n",
    "\n",
    "PROJECT_ROOT = Path(sys.path[0]).parent.resolve()\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "\n",
    "from src.utils import load_data\n",
    "from src.modules import ResNetRankNet\n",
    "from src.datasets import FlowPhotoDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = SimpleNamespace(\n",
    "    inference_data_file=\"/home/amritagupta/ssdprivate/data/Streamflow/fpe_stations/West Brook Lower_01171090/FLOW_CFS/images.csv\",\n",
    "    inference_image_root_dir=\"/home/amritagupta/ssdprivate/data/Streamflow/fpe_stations/West Brook Lower_01171090/FLOW_CFS\",\n",
    "    col_label='value',\n",
    "    img_sample_mean=[0.35581599, 0.34419223, 0.2620608],\n",
    "    img_sample_std=[0.22301329, 0.22242821, 0.22193837],\n",
    "    augment=True,\n",
    "    normalize=True,\n",
    "    batch_size=64,\n",
    "    gpu=0,\n",
    "    ckpt_path = '../../../edge-device-fpe-model-test/model.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(Path.exists(Path(args.ckpt_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_transforms(\n",
    "    resize_shape,\n",
    "    input_shape,\n",
    "    augmentation=True,\n",
    "    normalization=True,\n",
    "    means=None,\n",
    "    stds=None,\n",
    "):\n",
    "    image_transforms = {\n",
    "        \"train\": [\n",
    "            Resize(resize_shape),\n",
    "        ],\n",
    "        \"eval\": [\n",
    "            Resize(resize_shape),\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    # augmentation\n",
    "    image_transforms[\"train\"].extend(\n",
    "        [\n",
    "            RandomCrop(input_shape),\n",
    "            RandomHorizontalFlip(),\n",
    "            RandomRotation(10),\n",
    "            ColorJitter(),\n",
    "        ]  # type: ignore\n",
    "    ) if augmentation else image_transforms[\"train\"].append(\n",
    "        CenterCrop(input_shape)  # type: ignore\n",
    "    )  # type: ignore\n",
    "    image_transforms[\"eval\"].append(CenterCrop(input_shape))  # type: ignore\n",
    "\n",
    "    # normalization\n",
    "    if normalization:\n",
    "        image_transforms[\"train\"].append(Normalize(means, stds))  # type: ignore\n",
    "        image_transforms[\"eval\"].append(Normalize(means, stds))  # type: ignore\n",
    "\n",
    "    # composition\n",
    "    image_transforms[\"train\"] = Compose(image_transforms[\"train\"])  # type: ignore\n",
    "    image_transforms[\"eval\"] = Compose(image_transforms[\"eval\"])  # type: ignore\n",
    "    return image_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try to put data and model on GPU 0 for inference.\n",
      "Loaded model from checkpoint.\n"
     ]
    }
   ],
   "source": [
    "df = load_data(args.inference_data_file)\n",
    "ds = FlowPhotoDataset(df, args.inference_image_root_dir, col_label=args.col_label)\n",
    "image = ds.get_image(0)\n",
    "aspect = image.shape[2] / image.shape[1]\n",
    "# set up image transforms\n",
    "resize_shape = [480, np.int32(480 * aspect)]\n",
    "input_shape = [384, np.int32(384 * aspect)]\n",
    "image_transforms = create_image_transforms(\n",
    "    resize_shape,\n",
    "    input_shape,\n",
    "    means=args.img_sample_mean,\n",
    "    stds=args.img_sample_std,\n",
    "    augmentation=args.augment,\n",
    "    normalization=args.normalize,\n",
    ")\n",
    "ds.transform = image_transforms[\"eval\"]  # use eval transforms during inference\n",
    "dl = torch.utils.data.DataLoader(\n",
    "    ds, batch_size=args.batch_size, shuffle=False, num_workers=24\n",
    ")\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "# LOAD TRAINED MODEL\n",
    "# # # # # # # # # # # # # # # # # # # # # # # # #\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(f\"cuda:{args.gpu}\")\n",
    "    print(f\"Try to put data and model on GPU {args.gpu} for inference.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Try to put data and model on CPU for inference.\")\n",
    "model = ResNetRankNet(\n",
    "    input_shape=(3, input_shape[0], input_shape[1]),\n",
    "    resnet_size=18,\n",
    "    truncate=2,\n",
    "    pretrained=True,\n",
    ")\n",
    "model = torch.nn.DataParallel(\n",
    "    model,\n",
    "    # device_ids=[\n",
    "    #     args.gpu,\n",
    "    # ],\n",
    ")\n",
    "# model.to(device)\n",
    "checkpoint = torch.load(args.ckpt_path, map_location=device)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.eval()\n",
    "print(\"Loaded model from checkpoint.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on CPU.\n"
     ]
    }
   ],
   "source": [
    "# check if model is on GPU or CPU\n",
    "if next(model.parameters()).is_cuda:\n",
    "    print(\"Model is on GPU.\")\n",
    "else:\n",
    "    print(\"Model is on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on GPU.\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "# check now if model is on GPU or CPU\n",
    "if next(model.parameters()).is_cuda:\n",
    "    print(\"Model is on GPU.\")\n",
    "else:\n",
    "    print(\"Model is on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 384/1597 [01:35<02:32,  7.97it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      " 54%|█████▍    | 860/1597 [03:31<01:34,  7.83it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      " 69%|██████▉   | 1104/1597 [04:28<01:12,  6.83it/s]Corrupt JPEG data: 1 extraneous bytes before marker 0xd9\n",
      "100%|██████████| 1597/1597 [06:42<00:00,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scores = np.empty((len(dl.dataset),))\n",
    "sidx = 0\n",
    "with torch.no_grad():\n",
    "    for bidx, batch in tqdm(enumerate(dl), total=len(dl)):\n",
    "        inputs, labels = batch\n",
    "        nsamples = labels.shape[0]\n",
    "        outputs = model.module.forward_single(inputs.to(device))\n",
    "        scores[sidx : sidx + nsamples] = outputs.detach().cpu().numpy()\n",
    "        sidx += nsamples\n",
    "dl.dataset.table.loc[:, \"scores\"] = scores\n",
    "print(\"Inference complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fpe-model.dev-amrita",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
